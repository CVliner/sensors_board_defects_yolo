{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "PCB defects detected by YOLO v5",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2266446,
          "sourceType": "datasetVersion",
          "datasetId": 1364422
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'https%3A%2F%2Fstorage.googleapis.com%2Fdata-sets%2F1364422%2F2266446%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp--com%-161607.iam.gserviceaccount.com%252F20240523%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240523T194545Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D87e89e2a18a88570119e1526cefb93e85bf3fe57c3cadc2ee7e880741baddd97b412efceb82277290bdb9c702a10cbc0118c81b0f482199a419f99510126a3b94e651702cce7bc152784f5256813cbaebef04dd3f6c641551f59d398a5f7c932ac95e2dbc60af8d092d2d664031096d75b6a3516e3343c049f11c805f841330f923a11bc35ad78ce8f1e6d51f70c73e3bcc2340ff8078e837618568718696aea1c1344ded5319ad8e6eae471441417b91bf01519608d25e4294dfa5b26362bf4eca2af30af8c44060459e9f96d77034505fa7514210266a676fdce0acb3dfdeb2891cc9a187c0424d150c3ea3a55701c3d06a763bc0798eba4d7f9a179dfcd29'\n",
        "\n",
        "INPUT_PATH='/input'\n",
        "WORKING_PATH='/working'\n",
        "SYMLINK=''\n",
        "\n",
        "!umount /input/ 2> /dev/null\n",
        "shutil.rmtree('/input', ignore_errors=True)\n",
        "os.makedirs(INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "cDnNL61k_P2T"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset"
      ],
      "metadata": {
        "id": "n91-mtGzbC28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uEpPBHwjbI6C",
        "outputId": "b614a3af-2678-4830-d6a3-7f7969ac9cf0",
        "execution": {
          "iopub.status.busy": "2024-05-22T11:10:33.886279Z",
          "iopub.execute_input": "2024-05-22T11:10:33.886666Z",
          "iopub.status.idle": "2024-05-22T11:10:34.311013Z",
          "shell.execute_reply.started": "2024-05-22T11:10:33.886637Z",
          "shell.execute_reply": "2024-05-22T11:10:34.309441Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/drive/My Drive/Colab Notebooks/archive.zip'\n",
        "extracted_folder_path = '/content/data'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "print(f'ZIP The file has been successfully decompressed to \"{extracted_folder_path}\" The file has been successfully decompressed to the directory.')\n"
      ],
      "metadata": {
        "id": "6pXhzyS_PiEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data/DATASET"
      ],
      "metadata": {
        "id": "mVHIMb93cI98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "directory_path = '/content/data/DATASET'\n",
        "file_list = os.listdir(directory_path)\n",
        "\n",
        "print(\"Files in directory:\")\n",
        "for file_name in file_list:\n",
        "    print(file_name)"
      ],
      "metadata": {
        "id": "owRYiBq5cM4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "4OEQRN7T57yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check JPG quantities"
      ],
      "metadata": {
        "id": "8XlMSd77RZNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/data/DATASET/images'\n",
        "folders = ['Spurious_copper', 'Mouse_bite', 'Open_circuit', 'Missing_hole', 'Spur', 'Short']\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    jpg_count = len([f for f in os.listdir(folder_path) if f.endswith('.jpg')])\n",
        "    print(f\"{folder}: {jpg_count} JPG files\")"
      ],
      "metadata": {
        "id": "0xBa5JVuQ88_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check XML quantities"
      ],
      "metadata": {
        "id": "YpndvPYHAR4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "xml_folder_path = \"/content/data/DATASET/Annotations/\"\n",
        "\n",
        "xml_files = []\n",
        "for folder in ['Spurious_copper', 'Mouse_bite', 'Open_circuit', 'Missing_hole', 'Spur', 'Short']:\n",
        "    folder_path = os.path.join(xml_folder_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        xml_files.extend([os.path.join(folder, f) for f in os.listdir(folder_path) if f.endswith('.xml')])\n",
        "\n",
        "num_files = len(xml_files)\n",
        "print(f\"總共有 {num_files} 個XML檔案\")\n",
        "\n",
        "for folder in ['Spurious_copper', 'Mouse_bite', 'Open_circuit', 'Missing_hole', 'Spur', 'Short']:\n",
        "    folder_path = os.path.join(xml_folder_path, folder)\n",
        "    num_files_in_folder = len([f for f in os.listdir(folder_path) if f.endswith('.xml')])\n",
        "    print(f\"The file has been successfully decompressed to the directory. There are a total of. {num_files}  XML files\")"
      ],
      "metadata": {
        "id": "geYY2aUC-NF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "original_folder = '/content/PCB data/PCB_DATASET/images'\n",
        "resized_folder = '/content/PCB_resized'\n",
        "os.makedirs(resized_folder, exist_ok=True)\n",
        "folders = ['Spurious_copper', 'Mouse_bite', 'Open_circuit', 'Missing_hole', 'Spur', 'Short']\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(original_folder, folder)\n",
        "    images = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    os.makedirs(resized_folder, exist_ok=True)\n",
        "    for image in images:\n",
        "        image_path = os.path.join(folder_path, image)\n",
        "        img = Image.open(image_path)\n",
        "        resized_img = img.resize((640, 640))\n",
        "        output_path = os.path.join(resized_folder, image)\n",
        "        resized_img.save(output_path)\n",
        "        print(f\"Processed: {image}, new file saved in: {directory} {output_path}\")\n",
        "print(\"Processed: {image}, resized and saved to the new folder.\")"
      ],
      "metadata": {
        "id": "YDivB2VjbpOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "\n",
        "def resize_xml(xml_path, output_path, target_size):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for size in root.iter('size'):\n",
        "        width = int(size.find('width').text)\n",
        "        height = int(size.find('height').text)\n",
        "\n",
        "        size.find('width').text = str(target_size)\n",
        "        size.find('height').text = str(target_size)\n",
        "\n",
        "    for obj in root.iter('object'):\n",
        "        for box in obj.iter('bndbox'):\n",
        "            xmin = int(box.find('xmin').text)\n",
        "            ymin = int(box.find('ymin').text)\n",
        "            xmax = int(box.find('xmax').text)\n",
        "            ymax = int(box.find('ymax').text)\n",
        "\n",
        "            xmin = int(xmin * target_size / width)\n",
        "            ymin = int(ymin * target_size / height)\n",
        "            xmax = int(xmax * target_size / width)\n",
        "            ymax = int(ymax * target_size / height)\n",
        "\n",
        "            box.find('xmin').text = str(xmin)\n",
        "            box.find('ymin').text = str(ymin)\n",
        "            box.find('xmax').text = str(xmax)\n",
        "            box.find('ymax').text = str(ymax)\n",
        "\n",
        "    tree.write(output_path)\n",
        "\n",
        "original_annotations_folder = '/content/data/DATASET/Annotations'\n",
        "resized_annotations_folder = '/content/resized'\n",
        "os.makedirs(resized_annotations_folder, exist_ok=True)\n",
        "\n",
        "target_size = 640\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(original_annotations_folder, folder)\n",
        "\n",
        "    xml_files = [f for f in os.listdir(folder_path) if f.endswith('.xml')]\n",
        "    for xml_file in xml_files:\n",
        "        xml_path = os.path.join(folder_path, xml_file)\n",
        "\n",
        "        base_filename = os.path.splitext(xml_file)[0]\n",
        "        output_xml_path = os.path.join(resized_annotations_folder, f\"{base_filename}.xml\")\n",
        "        resize_xml(xml_path, output_xml_path, target_size)\n",
        "\n",
        "        print(f\"Processed: {xml_file}, new file saved in: {output_xml_path}\")\n",
        "\n",
        "print(\"Completed resizing XML files and saved to a new folder.\")\n"
      ],
      "metadata": {
        "id": "uA2C4g5LL0Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create train, val datasets and labels"
      ],
      "metadata": {
        "id": "ScyhmILQgjxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "source_folder = '/content/resized'\n",
        "\n",
        "output_folder = '/content/split'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.2\n",
        "\n",
        "for subset in ['train', 'val']:\n",
        "    os.makedirs(os.path.join(output_folder, subset), exist_ok=True)\n",
        "\n",
        "for xml_file in os.listdir(source_folder):\n",
        "    if xml_file.endswith('.xml'):\n",
        "        base_filename = os.path.splitext(xml_file)[0]\n",
        "\n",
        "        rand_num = random.random()\n",
        "        if rand_num < train_ratio:\n",
        "            subset_folder = 'train'\n",
        "        else:\n",
        "            subset_folder = 'val'\n",
        "\n",
        "        src_xml = os.path.join(source_folder, xml_file)\n",
        "        dest_xml = os.path.join(output_folder, subset_folder, f'{base_filename}.xml')\n",
        "        copyfile(src_xml, dest_xml)\n",
        "\n",
        "        jpg_file = f'{base_filename}.jpg'\n",
        "        src_jpg = os.path.join(source_folder, jpg_file)\n",
        "        dest_jpg = os.path.join(output_folder, subset_folder, jpg_file)\n",
        "        copyfile(src_jpg, dest_jpg)"
      ],
      "metadata": {
        "id": "UwARlc4xkwEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "\n",
        "def convert_xml_to_yolo(xml_path, image_width, image_height, class_mapping):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    labels = []\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        if class_name not in class_mapping:\n",
        "            continue\n",
        "\n",
        "        class_id = class_mapping[class_name]\n",
        "        bbox = obj.find('bndbox')\n",
        "\n",
        "        x_center = (float(bbox.find('xmin').text) + float(bbox.find('xmax').text)) / 2.0 / image_width\n",
        "        y_center = (float(bbox.find('ymin').text) + float(bbox.find('ymax').text)) / 2.0 / image_height\n",
        "        width = (float(bbox.find('xmax').text) - float(bbox.find('xmin').text)) / image_width\n",
        "        height = (float(bbox.find('ymax').text) - float(bbox.find('ymin').text)) / image_height\n",
        "\n",
        "        labels.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    return labels\n",
        "\n",
        "def create_yolo_labels(source_folder, output_folder, class_mapping):\n",
        "    for xml_file in os.listdir(source_folder):\n",
        "        if xml_file.endswith('.xml'):\n",
        "            xml_path = os.path.join(source_folder, xml_file)\n",
        "\n",
        "            image_file = os.path.splitext(xml_file)[0] + '.jpg'\n",
        "            image_path = os.path.join(source_folder.replace('Annotations', 'JPEGImages'), image_file)\n",
        "            img = Image.open(image_path)\n",
        "            image_width, image_height = img.size\n",
        "\n",
        "            labels = convert_xml_to_yolo(xml_path, image_width, image_height, class_mapping)\n",
        "\n",
        "            output_path = os.path.join(output_folder, os.path.splitext(xml_file)[0] + '.txt')\n",
        "            with open(output_path, 'w') as f:\n",
        "                f.write('\\n'.join(labels))\n",
        "\n",
        "class_mapping = {'spurious_copper': 0, 'mouse_bite': 1, 'open_circuit': 2, 'missing_hole': 3, 'spur': 4, 'short': 5}\n",
        "\n",
        "create_yolo_labels('/content/split/train', '/content/split/train', class_mapping)\n",
        "create_yolo_labels('/content/split/val', '/content/split/val', class_mapping)\n"
      ],
      "metadata": {
        "id": "i_Nq23ZVgthf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual inspection"
      ],
      "metadata": {
        "id": "Bb5RxNg2i8h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def visualize_random_image_with_labels(images_folder, labels_folder):\n",
        "    image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg')]\n",
        "\n",
        "    random_image_file = random.choice(image_files)\n",
        "    print(\"Randomly selected image:\", random_image_file)\n",
        "\n",
        "    image_path = os.path.join(images_folder, random_image_file)\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    label_file = os.path.splitext(random_image_file)[0] + '.txt'\n",
        "    label_path = os.path.join(labels_folder, label_file)\n",
        "\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            class_id = int(parts[0])\n",
        "            x_center, y_center, width, height = map(float, parts[1:])\n",
        "\n",
        "            img_height, img_width, _ = image.shape\n",
        "            x, y, w, h = map(int, [x_center * img_width, y_center * img_height, width * img_width, height * img_height])\n",
        "            x1, y1, x2, y2 = x - w//2, y - h//2, x + w//2, y + h//2\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "train_folder = '/content/split/train'\n",
        "labels_folder = '/content/split/train'\n",
        "\n",
        "visualize_random_image_with_labels(train_folder, labels_folder)"
      ],
      "metadata": {
        "id": "wx0EsFX3i88f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv5s model"
      ],
      "metadata": {
        "id": "ppobSSFEyoEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # Clone the YOLOv5 repository\n",
        "%cd yolov5\n",
        "!pip install -U -r requirements.txt  # Install dependencies"
      ],
      "metadata": {
        "id": "o_IGvQekO3fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml_content = \"\"\"\n",
        "\n",
        "train: /content/split/train\n",
        "val: /content/split/val\n",
        "nc: 6\n",
        "names: ['spurious_copper', 'mouse_bite', 'open_circuit', 'missing_hole', 'spur', 'short']\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/yolov5/data/data.yaml', 'w') as f:\n",
        "    f.write(data_yaml_content)"
      ],
      "metadata": {
        "id": "P7utkRGrUItn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img-size 640 --batch-size 16 --epochs 100 --data /content/yolov5/data/data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --name my_experiment --save-period 1 --project /content/yolov5/runs/"
      ],
      "metadata": {
        "id": "Gem5T0FLZj8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results_path = '/content/yolov5/runs/my_experiment/results.csv'\n",
        "df = pd.read_csv(results_path)\n",
        "\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "epochs = df['epoch']\n",
        "train_box_loss = df['train/obj_loss']\n",
        "val_box_loss = df['val/obj_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_box_loss, label='Train Object Loss', color='blue')\n",
        "plt.plot(epochs, val_box_loss, label='Validation Object Loss', color='orange')\n",
        "\n",
        "plt.title('Training and Validation Object Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Object Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9MxG5R51yTSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create test dataset"
      ],
      "metadata": {
        "id": "cH9eJlC08XUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_folder = '/content/data/DATASET/rotation'\n",
        "target_folder = '/content/rotation_test'\n",
        "\n",
        "os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "subfolders = ['Spurious_copper_rotation', 'Mouse_bite_rotation', 'Open_circuit_rotation', 'Missing_hole_rotation']\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(source_folder, subfolder)\n",
        "\n",
        "    for filename in os.listdir(subfolder_path):\n",
        "        if filename.endswith('.jpg'):\n",
        "            source_filepath = os.path.join(subfolder_path, filename)\n",
        "            target_filepath = os.path.join(target_folder, filename)\n",
        "            shutil.copy2(source_filepath, target_filepath)\n",
        "\n",
        "print(\"File copying completed!)\n"
      ],
      "metadata": {
        "id": "38us0cGo_Uzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "source_folder = '/content/rotation_test'\n",
        "target_folder = '/content/rotation_test_resized'\n",
        "\n",
        "os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(source_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        source_filepath = os.path.join(source_folder, filename)\n",
        "        img = Image.open(source_filepath)\n",
        "        img_resized = img.resize((640, 640))\n",
        "\n",
        "        target_filepath = os.path.join(target_folder, filename)\n",
        "        img_resized.save(target_filepath)\n",
        "\n",
        "print(\"File resizing completed!\")\n"
      ],
      "metadata": {
        "id": "hbsnZiNUApZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\"Send the JPG files in /content/rotation_test_resized to the previous model for testing."
      ],
      "metadata": {
        "id": "5IjG0wdGCr3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feed into the previous model training --> using best.pt\""
      ],
      "metadata": {
        "id": "2C6bzKXKB1FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/yolov5/runs/my_experiment/weights/best.pt --img-size 640 --conf 0.5 --source /content/rotation_test_resized --save-txt --save-conf --project /content/yolov5/runs/detect/"
      ],
      "metadata": {
        "id": "WDyw0IWaQGlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random visual inspection from test dataset"
      ],
      "metadata": {
        "id": "X6CMuwQZTOFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "original_folder = '/content/rotation_test_resized'\n",
        "result_folder = '/content/yolov5/runs/detect/exp'\n",
        "\n",
        "original_files = [f for f in os.listdir(original_folder) if f.endswith('.jpg')]\n",
        "\n",
        "selected_file = random.choice(original_files)\n",
        "selected_original_filepath = os.path.join(original_folder, selected_file)\n",
        "\n",
        "original_img = Image.open(selected_original_filepath)\n",
        "result_file = os.path.join(result_folder, selected_file)\n",
        "result_img = Image.open(result_file)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "axes[0].imshow(original_img)\n",
        "axes[0].set_title('Original Image')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(result_img)\n",
        "axes[1].set_title('Result Image')\n",
        "axes[1].axis('off')\n",
        "plt.show()\n",
        "print(\"File name:\", selected_file)\n",
        "\n",
        "label_filepath = os.path.join(result_folder, 'labels', os.path.splitext(selected_file)[0] + '.txt')\n",
        "if os.path.exists(label_filepath):\n",
        "    with open(label_filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            class_id, x_center, y_center, width, height = map(float, line.split()[1:])\n",
        "            print(f\"Category: {int(class_id)}, Position: [{x_center:.2f}, {y_center:.2f}, {width:.2f}, {height:.2f}]\")\n",
        "else:\n",
        "    print(f\"Label file not found. {label_filepath}\")\n"
      ],
      "metadata": {
        "id": "npwJSklAOMtR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}